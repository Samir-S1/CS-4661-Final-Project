{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7ad8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create imports for bassic pytorch lstm\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1003ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "# FashionMNIST is downloaded from the internet if not already present in './data'\n",
    "training_data = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67cc3de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FashionMNIST Dataset Head ===\n",
      "Training dataset size: 60000\n",
      "Test dataset size: 10000\n",
      "Number of classes: 10\n",
      "Batch size: 10\n",
      "Image shape: torch.Size([1, 28, 28])\n",
      "\n",
      "First 5 samples in this batch:\n",
      "Sample 1: Ankle boot   | Shape: torch.Size([1, 28, 28]) | Pixel range: [0.000, 1.000]\n",
      "Sample 2: T-shirt/top  | Shape: torch.Size([1, 28, 28]) | Pixel range: [0.000, 1.000]\n",
      "Sample 3: T-shirt/top  | Shape: torch.Size([1, 28, 28]) | Pixel range: [0.000, 1.000]\n",
      "Sample 4: Dress        | Shape: torch.Size([1, 28, 28]) | Pixel range: [0.000, 1.000]\n",
      "Sample 5: T-shirt/top  | Shape: torch.Size([1, 28, 28]) | Pixel range: [0.000, 1.000]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FashionMNIST class labels\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Get a small sample of data (first 5 items)\n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show basic dataset info\n",
    "print(\"=== FashionMNIST Dataset Head ===\")\n",
    "print(f\"Training dataset size: {len(training_data)}\")\n",
    "print(f\"Test dataset size: {len(test_data)}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Image shape: {images[0].shape}\")\n",
    "print()\n",
    "\n",
    "# Display first 5 samples as a simple overview\n",
    "print(\"First 5 samples in this batch:\")\n",
    "for i in range(5):\n",
    "    label_idx = labels[i].item()\n",
    "    img_shape = images[i].shape\n",
    "    pixel_range = f\"[{images[i].min():.3f}, {images[i].max():.3f}]\"\n",
    "    print(f\"Sample {i+1}: {class_names[label_idx]:<12} | Shape: {img_shape} | Pixel range: {pixel_range}\")\n",
    "\n",
    "# Show just the first 3 images in a simple row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "fig.suptitle('First 3 Samples from FashionMNIST', fontsize=14)\n",
    "\n",
    "for i in range(3):\n",
    "    img = images[i].squeeze().numpy()\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(f'{class_names[labels[i]]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "sequence_len = 28\n",
    "input_len = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01013c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_len, hidden_size, num_classes, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_len, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_state = torch.zeros(self.num_layers, x.size(0), self.hidden_size) # (num_layers, batch_size, hidden_size)\n",
    "        cell_state = torch.zeros(self.num_layers, x.size(0), self.hidden_size) # (num_layers, batch_size, hidden_size)\n",
    "        out, _ = self.lstm(x, (hidden_state, cell_state)) # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        out = self.output_layer(out[:, -1, :])  \n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_len, hidden_size, num_classes, num_layers)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "sgd = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "adam = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2aa1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, model, train_dataloader, loss_function):\n",
    "    total_step = len(train_dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch, (image, labels) in enumerate(train_dataloader):\n",
    "            images = image.reshape(-1, sequence_len, input_len)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch+1) % batch_size == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch+1}/{total_step}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e692f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(num_epochs, model, train_dataloader, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = next(iter(test_dataloader))\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fdbda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = model(test_images.view(-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = torch.max(test_output, 1)[1]\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = [1 for i in range(batch_size) if predicted[i] == test_labels[i]]\n",
    "percentage_correct = sum(correct)/batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2511fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99856d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
